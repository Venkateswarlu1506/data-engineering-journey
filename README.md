# ğŸš€ Data Engineering Journey with Python, Azure & Databricks

Welcome to my **Data Engineering Learning Repository**!  
This repo tracks my hands-on learning path in **Python, SQL, APIs, Databases, PySpark, Azure, Databricks, Kafka, Orchestration**, and end-to-end projects.

---

## ğŸ“‚ Repository Structure

01_python_sql/ â†’ Python + SQL foundations
02_apis/ â†’ API data extraction
03_databases/ â†’ PostgreSQL & MongoDB
04_pyspark/ â†’ Batch + Streaming with PySpark
05_adls_storage/ â†’ Azure Data Lake Storage
06_databricks/ â†’ ETL, Delta Lake, Databricks notebooks
07_synapse/ â†’ Azure Synapse Data Warehouse
08_kafka/ â†’ Apache Kafka streaming
09_orchestration/ â†’ Airflow & Azure Data Factory pipelines
10_projects/ â†’ End-to-End real-world projects

---

## ğŸ“Œ Learning Roadmap

âœ… **Python + SQL (Foundations)**  
âœ… **APIs (REST, JSON, Authentication, Data Extraction)**  
âœ… **Databases (PostgreSQL + MongoDB)**  
âœ… **PySpark (Batch + Stream Processing)**  
âœ… **Azure Data Lake (ADLS) + Storage**  
âœ… **Databricks (ETL + Delta Lake)**  
âœ… **Azure Synapse Analytics**  
âœ… **Apache Kafka (Message Queues & Streaming)**  
âœ… **Orchestration (Airflow + Azure Data Factory)**  
âœ… **End-to-End Projects (Real-World Pipelines)**  

---

## ğŸ“Š My Projects

### ğŸ”¹ Project 1: API â†’ Databricks â†’ Synapse  
- Extracted data from a **public API**  
- Processed with **PySpark in Databricks**  
- Loaded into **Azure Synapse Analytics**  

### ğŸ”¹ Project 2: Real-Time Streaming with Kafka & Spark  
- Kafka producer â†’ sends live data  
- Spark Structured Streaming â†’ transforms in real-time  
- Data stored in **Delta Lake + Synapse**  

---

## ğŸ› ï¸ Tech Stack

- **Programming**: Python, SQL, PySpark  
- **Databases**: PostgreSQL, MongoDB  
- **Big Data**: Databricks, Delta Lake  
- **Cloud**: Azure Data Lake, Synapse, Azure Data Factory  
- **Streaming**: Apache Kafka  
- **Orchestration**: Apache Airflow, ADF  
- **Version Control**: Git + GitHub  

---

## ğŸ“… Progress Tracker

| Module                | Status | Notes |
|------------------------|--------|-------|
| Python + SQL          | ğŸ”„ In Progress | |
| APIs                  | â³ Pending | |
| Databases             | â³ Pending | |
| PySpark               | â³ Pending | |
| Azure Data Lake       | â³ Pending | |
| Databricks            | â³ Pending | |
| Synapse               | â³ Pending | |
| Kafka                 | â³ Pending | |
| Orchestration         | â³ Pending | |
| Projects              | â³ Pending | |

---

## ğŸ“– About Me
Iâ€™m learning **Data Engineering + AI in Data** with a focus on **Azure & Databricks**.  
This repo is my **learning log + portfolio** to track projects, progress, and skills.

---

ğŸ’¡ **Tip**: Update this README every time you finish a milestone â†’ it shows growth over time.
-----------------------------------------------------------------------------------
1. Python Foundations for Data Engineering

Variables, data types, operators

Control structures (if, for, while)

Functions & modules

File handling (CSV, JSON, XML, TXT, Excel)

Error handling & logging (logging module)

Python libraries:

pandas â†’ for data manipulation

numpy â†’ for numerical computations

os, pathlib â†’ for file system interaction

requests â†’ for APIs

json, csv â†’ structured/unstructured data

2. Working with Databases (SQL + Python Integration)

SQL basics: SELECT, INSERT, UPDATE, DELETE

Joins, Aggregations, Window functions

Database design (normalization, primary keys, indexes)

Python connectors:

sqlite3

pyodbc / psycopg2 (Postgres)

sqlalchemy (ORM)

ETL with SQL + Python (extract from DB, transform in Python, load back)

3. Data Formats & Sources

CSV, TSV

JSON, XML

Parquet, ORC (big data formats)

APIs (REST, GraphQL)

Web scraping (BeautifulSoup, Scrapy)

Streaming data (Kafka basics)

4. Data Transformation & Processing

Batch Processing:

Pandas transformations

PySpark (for large datasets)

Dask (parallel computing)

Streaming Processing:

Kafka + Python consumers

Spark Structured Streaming

5. Data Storage Systems

Relational Databases (Postgres, MySQL, SQL Server)

NoSQL Databases:

MongoDB (document-based)

Cassandra (wide-column)

Redis (in-memory)

Data Lakes: Store raw files in S3, Azure Data Lake, GCP Storage

Data Warehouses: Snowflake, BigQuery, Azure Synapse, Redshift

6. Data Pipelines & Orchestration

ETL vs ELT concepts

Workflow orchestration tools:

Apache Airflow

Prefect

Luigi

Scheduling & monitoring pipelines

7. Big Data & Distributed Computing

Hadoop ecosystem (HDFS, MapReduce basics)

Spark (PySpark for transformations, joins, aggregations)

Delta Lake / Lakehouse concepts

8. Cloud & Modern Data Engineering

Azure (Databricks, Data Factory, Synapse)

AWS (Glue, Redshift, S3)

GCP (BigQuery, Dataflow, Pub/Sub)

Docker (containerization)

Kubernetes (for scaling pipelines)

9. Version Control & CI/CD

Git & GitHub/GitLab

Branching, merging, pull requests

CI/CD basics (Jenkins, GitHub Actions, GitLab CI)

10. Data Engineering Best Practices

Data quality & validation

Partitioning & bucketing for big data

Schema evolution

Handling duplicates & missing data

Logging & monitoring (Prometheus, Grafana)

âœ… Learning Path Suggestion for You:

Python basics â†’ Pandas/Numpy â†’ File handling

SQL + Python integration

Data formats (CSV, JSON, Parquet)

ETL project with Pandas + SQL

PySpark (batch + streaming)

Orchestration (Airflow/Prefect)

Cloud platform (Databricks on Azure would be perfect for you ğŸš€)
